{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec1eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cup-to-Disc Ratio (CDR): 0.7745685935830088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec 10 11:25:55 2024\n",
    "\n",
    "@author: kamand\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import sys\n",
    "from PyQt5.QtWidgets import (\n",
    "    QApplication,\n",
    "    QMainWindow,\n",
    "    QLabel,\n",
    "    QPushButton,\n",
    "    QVBoxLayout,\n",
    "    QHBoxLayout,\n",
    "    QFileDialog,\n",
    "    QWidget,\n",
    "    QButtonGroup,\n",
    ")\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtWidgets import QMessageBox\n",
    "file_path = 0;\n",
    "\n",
    "class GetImageAndAddModule(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Add your patient's Image\")\n",
    "        self.setGeometry(100, 100, 500, 500)\n",
    "        self.setStyleSheet(\"background-color: black; color: white\")\n",
    "        self.central_widget = QWidget()\n",
    "        self.setCentralWidget(self.central_widget)\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.images = QHBoxLayout()\n",
    "        \n",
    "        \n",
    "        # title of loading\n",
    "        self.image_label = QLabel(\"Load an image of your patient\")\n",
    "   #     self.preprocessed_label1 = QLabel(\"pre images 1\")\n",
    "     #   self.preprocessed_label2 = QLabel(\"pre image 2\")\n",
    "      #  self.preprocessed_label3 = QLabel(\"pre image 3\")\n",
    "        \n",
    "        \n",
    "        self.image_label.setStyleSheet(\"\"\"\n",
    "                                       background-color: #1b2b2b; \n",
    "                                       color : white;\n",
    "                                       border: 2px solid white; \n",
    "                                       \"\"\"\n",
    "            ) \n",
    "        self.image_label.setAlignment(Qt.AlignCenter) \n",
    "        self.image_label.mousePressEvent = self.clicked_thetopmessage\n",
    "        self.layout.addWidget(self.image_label)\n",
    "\n",
    "        # Here I'm adding button\n",
    "        \n",
    "        \n",
    "        self.process_button = QPushButton(\"PreProcessing\")\n",
    "        self.process_button.setStyleSheet(\"\"\"\n",
    "                                             QPushButton{\n",
    "                                                 \n",
    "                                                 background-color: #4CAF50; \n",
    "                                                 color: white; \n",
    "                                                 font-weight : bold;\n",
    "                                                 border = 2px solid white;\n",
    "                                                 padding = 5px;\n",
    "                              }\n",
    "                            \"\"\"\n",
    "            )     \n",
    "        self.process_button.clicked.connect(self.processing)\n",
    "        self.layout.addWidget(self.process_button)\n",
    "        \n",
    "        \n",
    "        self.load_image_button = QPushButton(\"Load Image\")\n",
    "        self.load_image_button.setStyleSheet(\"\"\"\n",
    "                                             QPushButton{\n",
    "                                                 \n",
    "                                                 background-color: #4CAF50; \n",
    "                                                 color: white; \n",
    "                                                 font-weight : bold;\n",
    "                                                 border = 2px solid white;\n",
    "                                                 padding = 5px;\n",
    "                              }\n",
    "                            \"\"\"\n",
    "            )\n",
    "        \n",
    "        self.load_image_button.clicked.connect(self.load_image)\n",
    "        self.layout.addWidget(self.load_image_button)\n",
    "\n",
    "        \n",
    "        self.button1 = QPushButton(\"SVM\")\n",
    "        self.button1.setStyleSheet(\"\"\"\n",
    "                                   QPushButton {\n",
    "                                       background-color: #2b2b2b;\n",
    "                                       color: white;\n",
    "                                       font-weight = bold;\n",
    "                                       border : 2px sold white;\n",
    "                                       padding : 5px;\n",
    "                \n",
    "                    }\n",
    "                    \"\"\"\n",
    "            )\n",
    "        self.button1.clicked.connect(self.SVM)\n",
    "        self.layout.addWidget(self.button1)\n",
    "\n",
    "\n",
    "\n",
    "        self.button2 = QPushButton(\"K-Means\")\n",
    "        self.button2.setStyleSheet(\"\"\"\n",
    "                                   QPushButton {\n",
    "                                       background-color: #2b2b2b;\n",
    "                                       color: white;\n",
    "                                       font-weight = bold;\n",
    "                                       border : 2px sold white;\n",
    "                                       padding : 5px;\n",
    "                                       \n",
    "                                       }\n",
    "                                   \"\"\"\n",
    "           \n",
    "            )\n",
    "        self.button2.clicked.connect(self.K_Means)\n",
    "        self.layout.addWidget(self.button2)\n",
    "        booly = 0;\n",
    "\n",
    "\n",
    "        self.button3 = QPushButton(\"Decision Tree\")\n",
    "        self.button3.setStyleSheet(\"\"\"\n",
    "                                   \n",
    "                                   \n",
    "                                   QPushButton {\n",
    "                                       background-color: #2b2b2b;\n",
    "                                       color: white;\n",
    "                                       font-weight = bold;\n",
    "                                       border : 2px sold white;\n",
    "                                       padding : 5px;\n",
    "                \n",
    "                                      }\n",
    "                                   \"\"\"\n",
    "           \n",
    "            )\n",
    "        self.button3.clicked.connect(self.DT)\n",
    "        self.layout.addWidget(self.button3)\n",
    "        \n",
    "        self.central_widget.setLayout(self.layout)\n",
    "        \n",
    "    def show_message(self, message): \n",
    "        msg_box = QMessageBox(self)\n",
    "        msg_box.setIcon(QMessageBox.Information)\n",
    "        msg_box.setText(message)\n",
    "        msg_box.setWindowTitle(\"Hows The Import Going? \")\n",
    "        msg_box.setStyleSheet(\"background-color: #1b2b2b; color: white\")\n",
    "        msg_box.exec_()\n",
    "        \n",
    "\n",
    "    def load_image(self):\n",
    "        \"\"\"Open file dialog to load an image.\"\"\"\n",
    "        options = QFileDialog.Options()\n",
    "        file_path, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Open Image\", \"\", \"Image Files (*.png *.jpg *.jpeg *.bmp)\", \n",
    "            options=options\n",
    "        )\n",
    "        if file_path:\n",
    "            self.file_path = file_path\n",
    "            pixmap = QPixmap(file_path)\n",
    "            self.image_label.setPixmap(pixmap.scaled(400, 400)) # Scale image to fit\n",
    "            self.show_message(\"Image Imported Successfully!\")\n",
    "        else:\n",
    "            self.show_message(\"Couldn't Get The Image From This Destination\")\n",
    "    #here you'll have the image destination\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def clicked_thetopmessage(self, event):\n",
    "        self.load_image()\n",
    "#when you're pressing the exit button if you press the exit button the code should be shutted\n",
    "\n",
    "    def ask_continue_or_quit(self, action_name):\n",
    "                reply = QMessageBox.question(\n",
    "                self,\n",
    "                \"continue or quit?\",\n",
    "                f\"{action_name} executed successfully! \\n\\n Do you want to continue? or may I quit.\",\n",
    "                QMessageBox.Yes | QMessageBox.No,\n",
    "                QMessageBox.Yes,\n",
    "                )\n",
    "            \n",
    "                if reply == QMessageBox.Yes:\n",
    "                    self.show_message(\"You chose to continue you may choose another algorithm\\n press Ok and start again!\")\n",
    "                else :\n",
    "                    QApplication.quit()\n",
    "                \n",
    "    def processing (self):\n",
    "        \n",
    "        original_image = cv2.imread(self.file_path)\n",
    "\n",
    "        # Convert to RGB\n",
    "        img_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # Stage 1: CLAHE on RGB channels\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        r, g, b = cv2.split(img_rgb)\n",
    "        r_clahe = clahe.apply(r)\n",
    "        g_clahe = clahe.apply(g)\n",
    "        b_clahe = clahe.apply(b)\n",
    "        img_clahe = cv2.merge((r_clahe, g_clahe, b_clahe))\n",
    "        output_path = 'image_clahe.jpg'  \n",
    "        cv2.imwrite(output_path, img_clahe)\n",
    "\n",
    "        # Stage 2: Thresholding (Disc and Cup)\n",
    "        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        gaussian_window_size = 5\n",
    "        gray_gaussian = cv2.GaussianBlur(gray, (gaussian_window_size, gaussian_window_size), 0)\n",
    "    \n",
    "        # Calculate thresholds\n",
    "        sigma_G = np.std(gray_gaussian)\n",
    "        sigma_RI = np.std(img_rgb[:, :, 0])  # Red channel\n",
    "        sigma_GI = np.std(img_rgb[:, :, 1])  # Green channel\n",
    "        mu_GI = np.mean(img_rgb[:, :, 1])   # Green channel mean\n",
    "        T1 = (0.5 * gaussian_window_size) - (2 * sigma_G) - sigma_RI\n",
    "        T2 = (0.5 * gaussian_window_size) + (2 * sigma_G) + (2 * sigma_GI) + mu_GI\n",
    "    \n",
    "        # Apply thresholds\n",
    "        _, thresh_disc = cv2.threshold(gray, abs(T1), 255, cv2.THRESH_BINARY)\n",
    "        _, thresh_cup = cv2.threshold(gray, T2, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Apply morphological opening and closing\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))\n",
    "        morph_open_disc = cv2.morphologyEx(thresh_disc, cv2.MORPH_OPEN, kernel)\n",
    "        morph_close_disc = cv2.morphologyEx(morph_open_disc, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        morph_open_cup = cv2.morphologyEx(thresh_cup, cv2.MORPH_OPEN, kernel)\n",
    "        morph_close_cup = cv2.morphologyEx(morph_open_cup, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours\n",
    "        contours_disc, _ = cv2.findContours(morph_close_disc, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_cup, _ = cv2.findContours(morph_close_cup, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Apply convex hull to the contours\n",
    "        hull_disc = [cv2.convexHull(cnt) for cnt in contours_disc]\n",
    "        hull_cup = [cv2.convexHull(cnt) for cnt in contours_cup]\n",
    "\n",
    "        # Draw contours on a blank image\n",
    "        blank_disc = np.zeros_like(morph_close_disc)\n",
    "        blank_cup = np.zeros_like(morph_close_cup)\n",
    "        cv2.drawContours(blank_disc, hull_disc, -1, (255), -1)\n",
    "        cv2.drawContours(blank_cup, hull_cup, -1, (255), -1)\n",
    "\n",
    "\n",
    "        # Find largest contour (assuming the largest contour corresponds to the region of interest)\n",
    "        largest_disc = max(hull_disc, key=cv2.contourArea)\n",
    "        largest_cup = max(hull_cup, key=cv2.contourArea)\n",
    "\n",
    "        # Fit ellipse to the largest contours\n",
    "        ellipse_disc = cv2.fitEllipse(largest_disc)\n",
    "        ellipse_cup = cv2.fitEllipse(largest_cup)\n",
    "\n",
    "        # Draw ellipses on a blank image\n",
    "        result_image = np.zeros_like(original_image)\n",
    "        cv2.ellipse(result_image, ellipse_disc, (255, 0, 0), 2)  # Disc in red\n",
    "        cv2.ellipse(result_image, ellipse_cup, (0, 255, 0), 2)  # Cup in green\n",
    "\n",
    "        # Calculate major axes\n",
    "        major_axis_disc = max(ellipse_disc[1])\n",
    "        major_axis_cup = max(ellipse_cup[1])\n",
    "\n",
    "        # Compute CDR\n",
    "        cdr = major_axis_cup / major_axis_disc\n",
    "        print(f\"Cup-to-Disc Ratio (CDR): {cdr}\")\n",
    "\n",
    "        output_path3 = 'blank_disc.jpg'  \n",
    "        cv2.imwrite(output_path3, blank_disc)\n",
    "        output_path4 = 'blank_cup.jpg'  \n",
    "        cv2.imwrite(output_path4, blank_cup)\n",
    "        output_path5 = 'result_image.jpg'  \n",
    "        cv2.imwrite(output_path5, result_image)\n",
    "\n",
    "        self.show_processed_images(\"result_image.jpg\", \"blank_disc.jpg\", \"blank_cup.jpg\")\n",
    "        self.show_message(f\"The calculated value of CDR is: {cdr}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def show_processed_images(self, processed_image1, processed_image2, \n",
    "                                          processed_image3 ) :\n",
    "        self.window = QWidget()\n",
    "        self.window.setWindowTitle(\"Processed Images\")\n",
    "        self.window.setGeometry(200, 100, 1200, 400)\n",
    "        \n",
    "        \n",
    "        image_layout = QHBoxLayout()\n",
    "        \n",
    "        image_label0 = QLabel(\"Preprocess1\")\n",
    "        image_label0.setStyleSheet(\"\"\"\n",
    "                                       background-color: #1b2b2b; \n",
    "                                       color : white;\n",
    "                                       border: 2px solid white; \n",
    "                                       \"\"\"\n",
    "            ) \n",
    "        image_label0.setAlignment(Qt.AlignCenter) \n",
    "        \n",
    "        image_label1 = QLabel(\"Preprocess2\")\n",
    "        image_label1.setStyleSheet(\"\"\"\n",
    "                                       background-color: #1b2b2b; \n",
    "                                       color : white;\n",
    "                                       border: 2px solid white; \n",
    "                                       \"\"\"\n",
    "            ) \n",
    "        image_label1.setAlignment(Qt.AlignCenter) \n",
    "        \n",
    "\n",
    "        image_label2 = QLabel(\"Preprocess3\")\n",
    "        image_label2.setStyleSheet(\"\"\"\n",
    "                                       background-color: #1b2b2b; \n",
    "                                       color : white;\n",
    "                                       border: 2px solid white; \n",
    "                                       \"\"\"\n",
    "            ) \n",
    "        image_label2.setAlignment(Qt.AlignCenter) \n",
    "        \n",
    "        \n",
    "        \n",
    "        image_layout.addWidget(image_label0)\n",
    "        image_layout.addWidget(image_label1)\n",
    "        image_layout.addWidget(image_label2)\n",
    "        \n",
    "        pixmap = QPixmap(processed_image1)\n",
    "        image_label0.setPixmap(pixmap.scaled(400, 400))\n",
    "        \n",
    "        pixmap = QPixmap(processed_image2)\n",
    "        image_label1.setPixmap(pixmap.scaled(400, 400))\n",
    "        \n",
    "        pixmap = QPixmap(processed_image3)\n",
    "        image_label2.setPixmap(pixmap.scaled(400, 400))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.window.setLayout(image_layout)\n",
    "        self.window.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \"\"\"def convert_cv_to_pixmap(self, cv_image, is_grayscale = False) :\n",
    "        \n",
    "        cv2.imshow(\"hi\", cv_image)\n",
    "        \n",
    "        a = QImage(cv_image.data, cv_image.shape[1], cv_image.shape[0], QImage.Format_RGB888).rgbSwapped()\n",
    "        \n",
    "        return QPixmap.fromImage(a)\n",
    "        \n",
    "        \n",
    "        if is_grayscale :\n",
    "            height, width, channel = cv_image.shape\n",
    "            bytes_per_line = width\n",
    "            q_image = QImage(cv_image.data, width, height, bytes_per_line,\n",
    "                             QImage.Format_Grayscale8)\n",
    "        \n",
    "        else:\n",
    "            rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "            height, width, channel = rgb_image.shape\n",
    "            bytes_per_line = channel * width\n",
    "            q_image = QImage(rgb_image.data, width, height, bytes_per_line,\n",
    "                             QImage.Format_Grayscale8\n",
    "                                 )\n",
    "        \n",
    "        return QPixmap.fromImage(q_image)\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "    def SVM(self):\n",
    "        #add the first module here\n",
    "        # Load the CNN model\n",
    "        self.model = load_model('my_cnn_model.h5')\n",
    "        # Load the SVM model\n",
    "        with open('my_svm_model.pkl', 'rb') as file:\n",
    "             svm_model = pickle.load(file)\n",
    "           \n",
    "        # Preprocess the image and predict using the CNN model\n",
    "        image = cv2.imread(self.file_path)\n",
    "        image = cv2.resize(image, (224, 224)) # Adjust size as needed\n",
    "        image = image / 255.0  # Normalize the image\n",
    "        image = numpy.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "        cnn_prediction = self.model.predict(image)\n",
    "           \n",
    "        # Concatenate CDR value to the CNN output\n",
    "        concatenated_output = numpy.append(cnn_prediction, [0.4])  # Example number to concatenate\n",
    "           \n",
    "        # Predict using the SVM model\n",
    "        svm_prediction = svm_model.predict([concatenated_output])\n",
    "#         print(svm_prediction[0])\n",
    "           \n",
    "        #define the boolean with name booly\n",
    "        booly = svm_prediction[0]\n",
    "        if booly == '1' :\n",
    "            self.show_message(\"Unfortunately  Your Patient Has Glaucoma.\")\n",
    "\n",
    "        else : \n",
    "            self.show_message(\"Your Patient is Healthy.\")\n",
    "        \n",
    "        self.ask_continue_or_quit(\"SVM\")\n",
    "\n",
    "    def K_Means(self):\n",
    "        # Load the CNN model\n",
    "        self.model = load_model('cnn_model.h5')\n",
    "        \n",
    "        # Load the KMeans model\n",
    "        with open('kmeans_model.pkl', 'rb') as file:\n",
    "            kmeans_model = pickle.load(file)\n",
    "        \n",
    "        # Load the saved scaler and PCA models\n",
    "        with open('scaler.pkl', 'rb') as file:\n",
    "            scaler = pickle.load(file)\n",
    "        \n",
    "        with open('pca.pkl', 'rb') as file:\n",
    "            pca = pickle.load(file)\n",
    "        \n",
    "        # Preprocess the image and predict using the CNN model\n",
    "        image = cv2.imread(self.file_path)\n",
    "        image = cv2.resize(image, (224, 224))  # Resize image\n",
    "        image = image / 255.0  # Normalize\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        \n",
    "        cnn_prediction = self.model.predict(image)\n",
    "        \n",
    "        # Concatenate CDR value to the CNN output\n",
    "        cdr_value = 0.4 # Example CDR value; replace with calculated CDR\n",
    "        concatenated_output = np.append(cnn_prediction.flatten(), [cdr_value])\n",
    "        concatenated_output = concatenated_output.reshape(1, -1)  # Reshape to 2D array\n",
    "\n",
    "        \n",
    "        # Normalize and apply PCA to match KMeans input\n",
    "        concatenated_output_scaled = scaler.transform(concatenated_output)\n",
    "        concatenated_output_pca = pca.transform(concatenated_output_scaled)\n",
    "        \n",
    "        # Predict using the KMeans model\n",
    "        kmeans_prediction = kmeans_model.predict(concatenated_output_pca)\n",
    "        \n",
    "        # Show result\n",
    "        booly = kmeans_prediction[0]\n",
    "        if booly == '1':\n",
    "            self.show_message(\"Unfortunately, your patient has Glaucoma.\")\n",
    "        else:\n",
    "            self.show_message(\"Your patient is healthy.\")\n",
    "        \n",
    "        self.ask_continue_or_quit(\"K-Means\")\n",
    "\n",
    "    def DT(self):\n",
    "        #add the third module here\n",
    "        # Load the CNN model\n",
    "        self.model = load_model('my_cnn_model.h5')\n",
    "        # Load the DT model\n",
    "        with open('my_dt_model.pkl', 'rb') as file:\n",
    "             dt_model = pickle.load(file)\n",
    "        \n",
    "        # Preprocess the image and predict using the CNN model\n",
    "        image = cv2.imread(self.file_path)\n",
    "        image = cv2.resize(image, (224, 224)) # Adjust size as needed\n",
    "        image = image / 255.0  # Normalize the image\n",
    "        image = numpy.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "        cnn_prediction = self.model.predict(image)\n",
    "           \n",
    "         # Concatenate CDR value to the CNN output\n",
    "        concatenated_output = numpy.append(cnn_prediction, [0.4])  # Example number to concatenate\n",
    "           \n",
    "        # Predict using the DT model\n",
    "        dt_prediction = dt_model.predict([concatenated_output])\n",
    "           \n",
    "        #define the boolean with name booly\n",
    "        booly = dt_prediction[0]\n",
    "        if booly == '1' :\n",
    "            self.show_message(\"Unfortunately  Your Patient Has Glaucoma.\")\n",
    "\n",
    "        else : \n",
    "            self.show_message(\"Your Patient is Healthy.\")\n",
    "        \n",
    "        self.ask_continue_or_quit(\"DT\")\n",
    "            \n",
    "\n",
    "   \n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        reply = QMessageBox.question(self, \n",
    "                                     \"Exit Application?\", \n",
    "                                     \"Are you sure you want to exit?\" ,\n",
    "                                     QMessageBox.No | QMessageBox.Yes,\n",
    "                                     QMessageBox.No\n",
    "                                     )\n",
    "                                     \n",
    "        if reply == QMessageBox.Yes :\n",
    "            event.accept()\n",
    "            QApplication.quit()\n",
    "        else:\n",
    "            event.ignore()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    app = QApplication(sys.argv)\n",
    "    window = GetImageAndAddModule()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
